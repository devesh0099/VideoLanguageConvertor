{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdlyxP21Mvnq"
   },
   "source": [
    "### VoxLingua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoNsbOu8JgLP"
   },
   "source": [
    "##Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPFMDGAVS8ws"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNi1t1Z6JlmX"
   },
   "source": [
    "## Extracting Audio\n",
    "This cell is used to extract audio from a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjsOCWQ5MXyA"
   },
   "outputs": [],
   "source": [
    "#Converting .mp4 to wav file\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\n",
    "\n",
    "def convert_video_to_audio(video_path, audio_path):\n",
    "    try:\n",
    "        video = VideoFileClip(video_path)\n",
    "        audio = video.audio\n",
    "        audio.write_audiofile(audio_path, codec='pcm_s16le')  # Saving as WAV format\n",
    "        print(\"Audio file successfully created!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "video_path = \"/content/video.mp4\"  # TODO:Upgrade to support other codecs\n",
    "file_name = video_path[9:-4]\n",
    "audio_path = video_path[0:-4] + \".wav\"\n",
    "convert_video_to_audio(video_path, audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiprhO70JwOf"
   },
   "source": [
    "## Wisper Model\n",
    "This model helps recognize the language of the video and transcript it.\n",
    "Also, this cell splits the transcript into one sentence chunk and stores it in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xs6gfh5ZNhiZ"
   },
   "outputs": [],
   "source": [
    "#Speech To Text\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "result = pipe(audio_path)\n",
    "Transcript = result['text']\n",
    "print(result)\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZrEooXLKy0N"
   },
   "source": [
    "## Translation Model\n",
    "This model translates the transcript on a per-sentence basis and outputs it back in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQc9Zub2Ev2B"
   },
   "outputs": [],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "model_t = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer_t = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "Translated_Transcript = []\n",
    "\n",
    "splited_transcript = Transcript.split(\".\")\n",
    "\n",
    "for i in splited_transcript:\n",
    "  tokenizer_t.src_lang = \"en\"\n",
    "  encoded_hi = tokenizer_t(i, return_tensors=\"pt\")\n",
    "  generated_tokens = model_t.generate(**encoded_hi, forced_bos_token_id=tokenizer_t.get_lang_id(\"hi\")).to(device)\n",
    "  l = tokenizer_t.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "  Translated_Transcript.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTm1QMRTLC1x"
   },
   "source": [
    "Misc Cell for handling TTS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G3JcdsSdYRLh"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6BBIScSLIr0"
   },
   "source": [
    "## Restarting Session\n",
    "These cells stores the local variables in a file then on restarting the session reload the variables.\n",
    "This is a workaround for limited resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAr9ttmBt8JF"
   },
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op-TOq6MLo84"
   },
   "source": [
    "Saving Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nP955zlztXQy"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from google.colab import files\n",
    "joblib.dump(result,  'result.pkl')\n",
    "joblib.dump(Transcript,  'Transcript.pkl')\n",
    "joblib.dump(Translated_Transcript,  'Translated_Transcript.pkl')\n",
    "joblib.dump(splited_transcript,  'splited_transcript.pkl')\n",
    "joblib.dump(video_path,'video_path.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UIHWIKLLli2"
   },
   "source": [
    "Reloading Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PNnXh3gMuvRH"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "result = joblib.load('result.pkl')\n",
    "Transcript = joblib.load('Transcript.pkl')\n",
    "Translated_Transcript = joblib.load('Translated_Transcript.pkl')\n",
    "splited_transcript = joblib.load('splited_transcript.pkl')\n",
    "video_path = joblib.load('video_path.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ml3v99TuyIaG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlEdSP4VLe7S"
   },
   "source": [
    "## TTS Model\n",
    "This model converts the translated transcript into proper pronunciation of that language with a voice cloning feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxqmnO4JhBy3"
   },
   "outputs": [],
   "source": [
    "!pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IKGZFtj_IhF"
   },
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZsy8hG2_Y5H"
   },
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "tts.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "743pXKkML8nx"
   },
   "source": [
    "In addition to voice cloning all the separated sentences got merged into a single wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pWS_7GrhDmW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "output_directory = \"/content/sentence_audio/\"\n",
    "final_output_path = \"/content/output.wav\"\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "combined_audio = AudioSegment.empty()\n",
    "\n",
    "for idx, sentence in enumerate(Translated_Transcript):\n",
    "    text_translated = sentence[0]\n",
    "    temp_file_path = os.path.join(output_directory, f\"sentence_{idx}.wav\")\n",
    "    tts.tts_to_file(\n",
    "        text=text_translated,\n",
    "        file_path=temp_file_path,\n",
    "        speaker_wav=\"/content/video.wav\",\n",
    "        language=\"hi\"\n",
    "    )\n",
    "\n",
    "    audio_segment = AudioSegment.from_wav(temp_file_path)\n",
    "    combined_audio += audio_segment\n",
    "\n",
    "combined_audio.export(final_output_path, format=\"wav\")\n",
    "\n",
    "for idx in range(len(Translated_Transcript)):\n",
    "    temp_file_path = os.path.join(output_directory, f\"sentence_{idx}.wav\")\n",
    "    if os.path.exists(temp_file_path):\n",
    "        os.remove(temp_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbUZTfMVMiN-"
   },
   "source": [
    "## Merging Video and Audio\n",
    "Separated Video File And Audio file merged into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylaqTaNmIeON"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "original_video = VideoFileClip(video_path)\n",
    "\n",
    "new_audio = AudioFileClip(\"output.wav\")\n",
    "\n",
    "final_clip = original_video.set_audio(new_audio)\n",
    "\n",
    "final_clip.write_videofile(\"final_video.mp4\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
